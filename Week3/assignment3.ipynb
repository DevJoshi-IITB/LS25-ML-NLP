{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:15:25.970740Z",
     "iopub.status.busy": "2025-07-01T11:15:25.970042Z",
     "iopub.status.idle": "2025-07-01T11:15:25.975206Z",
     "shell.execute_reply": "2025-07-01T11:15:25.974206Z",
     "shell.execute_reply.started": "2025-07-01T11:15:25.970713Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# import evaluate\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:15:28.705430Z",
     "iopub.status.busy": "2025-07-01T11:15:28.704706Z",
     "iopub.status.idle": "2025-07-01T11:15:31.508490Z",
     "shell.execute_reply": "2025-07-01T11:15:31.507905Z",
     "shell.execute_reply.started": "2025-07-01T11:15:28.705401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:16:05.163757Z",
     "iopub.status.busy": "2025-07-01T11:16:05.163435Z",
     "iopub.status.idle": "2025-07-01T11:16:05.910155Z",
     "shell.execute_reply": "2025-07-01T11:16:05.909309Z",
     "shell.execute_reply.started": "2025-07-01T11:16:05.163734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:16:08.743627Z",
     "iopub.status.busy": "2025-07-01T11:16:08.742954Z",
     "iopub.status.idle": "2025-07-01T11:16:09.012621Z",
     "shell.execute_reply": "2025-07-01T11:16:09.011629Z",
     "shell.execute_reply.started": "2025-07-01T11:16:08.743602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=69).select(range(1000))  \n",
    "test_dataset = tokenized_datasets[\"test\"].shuffle(seed=69).select(range(200))\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:16:11.943612Z",
     "iopub.status.busy": "2025-07-01T11:16:11.942756Z",
     "iopub.status.idle": "2025-07-01T11:16:11.948423Z",
     "shell.execute_reply": "2025-07-01T11:16:11.947414Z",
     "shell.execute_reply.started": "2025-07-01T11:16:11.943579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:16:36.023271Z",
     "iopub.status.busy": "2025-07-01T11:16:36.022541Z",
     "iopub.status.idle": "2025-07-01T11:16:36.058692Z",
     "shell.execute_reply": "2025-07-01T11:16:36.058088Z",
     "shell.execute_reply.started": "2025-07-01T11:16:36.023247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,  # log every 10 steps\n",
    "    report_to=\"none\",  # disable wandb etc.\n",
    "    disable_tqdm=False,  # show progress bar\n",
    "    fp16=True,  # enable faster training if on GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:16:38.572542Z",
     "iopub.status.busy": "2025-07-01T11:16:38.572264Z",
     "iopub.status.idle": "2025-07-01T11:18:41.542884Z",
     "shell.execute_reply": "2025-07-01T11:18:41.541813Z",
     "shell.execute_reply.started": "2025-07-01T11:16:38.572525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64/64 01:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.418680</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.324792</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.878505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64, training_loss=0.4148192321881652, metrics={'train_runtime': 122.1622, 'train_samples_per_second': 16.372, 'train_steps_per_second': 0.524, 'total_flos': 526222110720000.0, 'train_loss': 0.4148192321881652, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:51:27.637245Z",
     "iopub.status.busy": "2025-07-01T11:51:27.636286Z",
     "iopub.status.idle": "2025-07-01T11:51:31.270111Z",
     "shell.execute_reply": "2025-07-01T11:51:31.269500Z",
     "shell.execute_reply.started": "2025-07-01T11:51:27.637215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.3247924745082855, 'eval_accuracy': 0.87, 'eval_f1': 0.8785046728971961, 'eval_runtime': 3.6229, 'eval_samples_per_second': 55.204, 'eval_steps_per_second': 1.932, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:53:49.758585Z",
     "iopub.status.busy": "2025-07-01T11:53:49.758111Z",
     "iopub.status.idle": "2025-07-01T11:53:51.109737Z",
     "shell.execute_reply": "2025-07-01T11:53:51.108800Z",
     "shell.execute_reply.started": "2025-07-01T11:53:49.758556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment-bert/tokenizer_config.json',\n",
       " './sentiment-bert/special_tokens_map.json',\n",
       " './sentiment-bert/vocab.txt',\n",
       " './sentiment-bert/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./sentiment-bert\")\n",
    "tokenizer.save_pretrained(\"./sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T11:55:57.114831Z",
     "iopub.status.busy": "2025-07-01T11:55:57.114548Z",
     "iopub.status.idle": "2025-07-01T11:55:57.137534Z",
     "shell.execute_reply": "2025-07-01T11:55:57.136554Z",
     "shell.execute_reply.started": "2025-07-01T11:55:57.114811Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize and move to device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "sample_text = \"The movie was abysmal!\"\n",
    "print(f\"Sample Prediction: {predict_sentiment(sample_text)}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
